{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/Users/katekistler/anaconda3/envs/nextstrain/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make test data set to sanity check\n",
    "outgroup_test = ['ATGGAGATT']\n",
    "test_seqs = ['ATGGAGATT', 'ATGGAGAAT', 'ATGGAGATT',\n",
    "            'ATGGAGAAT', 'ATGGAGATC', 'ATCGAGATT',\n",
    "            'ATGGAGACT', 'ATGGAGATT', 'ATGGAGATT',\n",
    "            'ATGGGGATT', 'ATGCAGATT', 'ATGCAGATT', 'ATGGAGATT']\n",
    "test_dates = [2010, 2010, 2011,\n",
    "              2012, 2012,\n",
    "              2013, 2013, 2013,\n",
    "              2014, 2014, 2014, 2014]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a polymorphism frequency, return bin\n",
    "def frequency_binning(x):\n",
    "    #nan frequencies are when there is no sequence coverage at the given position\n",
    "    if math.isnan(x):\n",
    "        f_bin = float('nan')\n",
    "    else:\n",
    "        if x == 1.0:\n",
    "            f_bin = 'f'\n",
    "        elif x>=0.75:\n",
    "            f_bin = 'h'\n",
    "        elif x<0.75 and x>=0.15:\n",
    "            f_bin = 'm'\n",
    "        elif x<0.15:\n",
    "            f_bin='l'\n",
    "\n",
    "    return f_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_through_sites(outgroup_seq, outgroup_aa_seq, input_file_alignment, viruses):\n",
    "    \n",
    "    #at each site, count number of viruses with polymorphism\n",
    "    count_polymorphic = np.zeros(len(outgroup_seq))\n",
    "    #at each site, count totaly number of viruses\n",
    "    count_total_unambiguous = np.zeros(len(outgroup_seq))\n",
    "    \n",
    "    count_replacement_mutations = np.zeros(len(outgroup_seq))\n",
    "    count_silent_mutations = np.zeros(len(outgroup_seq))\n",
    "    \n",
    "    #at each site, list of nucleotide from each virus\n",
    "    ingroup_bases = [[] for x in range(len(outgroup_seq))]\n",
    "\n",
    "    with open(input_file_alignment, \"r\") as aligned_handle:\n",
    "        for virus in SeqIO.parse(aligned_handle, \"fasta\"):\n",
    "            #Only viruses in time window\n",
    "            if virus.id in viruses:\n",
    "                #check\n",
    "                if len(virus.seq) != len(outgroup_seq):\n",
    "                    print(virus)\n",
    "                elif len(virus.seq) == len(outgroup_seq):                   \n",
    "                    for pos in range(len(outgroup_seq)):\n",
    "                        outgroup_nt = str(outgroup_seq[pos])\n",
    "                        virus_nt = str(virus.seq[pos])\n",
    "                        #skip ambiguous sites\n",
    "                        if virus_nt != 'N':\n",
    "                            ingroup_bases[pos].append(virus_nt)\n",
    "                            count_total_unambiguous[pos]+=1\n",
    "                            if virus_nt != outgroup_nt:\n",
    "                                count_polymorphic[pos]+=1\n",
    "                                #determine silent or replacement\n",
    "                                codon = math.floor(pos/3)\n",
    "                                codon_pos = pos-(codon*3)\n",
    "                                if codon_pos == 0:\n",
    "                                    codon_nt = virus.seq[pos:(pos+3)]\n",
    "                                elif codon_pos == 1:\n",
    "                                    codon_nt = virus.seq[(pos-1):(pos+2)]\n",
    "                                elif codon_pos == 2:\n",
    "                                    codon_nt = virus.seq[(pos-2):(pos+1)]\n",
    "                                codon_aa = codon_nt.translate()\n",
    "                                outgroup_aa = outgroup_aa_seq[codon]\n",
    "                                if codon_aa != outgroup_aa:\n",
    "                                    count_replacement_mutations[pos]+=1\n",
    "                                elif codon_aa == outgroup_aa:\n",
    "                                    count_silent_mutations[pos]+=1\n",
    "                                \n",
    "    polymorphic_frequencies = count_polymorphic/count_total_unambiguous\n",
    "    \n",
    "    replacement_score = count_replacement_mutations/count_total_unambiguous\n",
    "\n",
    "    freq_bins = [frequency_binning(x) for x in polymorphic_frequencies]\n",
    "    \n",
    "    return freq_bins, replacement_score, ingroup_bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_site_type(outgroup, ingroup):\n",
    "    ingroup_bases_nan = set(ingroup)\n",
    "    #remove 'nan's\n",
    "    ingroup_bases = {x for x in ingroup_bases_nan if pd.notna(x)}\n",
    "    \n",
    "    if len(ingroup_bases) == 0:\n",
    "        site_type = None\n",
    "    \n",
    "    elif len(ingroup_bases) != 0:\n",
    "        #all ingroup bases are identical\n",
    "        if len(ingroup_bases) == 1:\n",
    "            if outgroup in ingroup_bases:\n",
    "                site_type = 1\n",
    "            elif outgroup not in ingroup_bases:\n",
    "                site_type = 2\n",
    "\n",
    "        #2 different bases in ingroup\n",
    "        elif len(ingroup_bases) == 2:\n",
    "            if outgroup in ingroup_bases:\n",
    "                site_type = 3\n",
    "            elif outgroup not in ingroup_bases:\n",
    "                site_type = 4\n",
    "\n",
    "        #3 different bases in ingroup\n",
    "        elif len(ingroup_bases) == 3:\n",
    "            if outgroup in ingroup_bases:\n",
    "                site_type = 5\n",
    "            elif outgroup not in ingroup_bases:\n",
    "                site_type = 6\n",
    "\n",
    "        #4 different bases in ingroup\n",
    "        elif len(ingroup_bases) == 4:\n",
    "            site_type = 7\n",
    "    \n",
    "    return site_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixation_polymorphism_score(outgroup, ingroup):\n",
    "    site_type = determine_site_type(outgroup, ingroup)\n",
    "    \n",
    "    if site_type == None:\n",
    "        Fi = float('nan')\n",
    "        Pi = float('nan')\n",
    "    if site_type == 1:\n",
    "        Fi = 0\n",
    "        Pi = 0\n",
    "    elif site_type == 2:\n",
    "        Fi = 1\n",
    "        Pi = 0\n",
    "    elif site_type in [3,5,7]:\n",
    "        Fi = 0\n",
    "        Pi = 1\n",
    "    elif site_type == 4:\n",
    "        Fi = 0.5\n",
    "        Pi = 0.5\n",
    "    elif site_type == 6:\n",
    "        Fi = (1/3)\n",
    "        Pi = (2/3)\n",
    "    \n",
    "    return Fi, Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_fi_pi(outgroup_seq, ingroup_bases):\n",
    "    \n",
    "    #at each site, record Fi\n",
    "    Fi_all = np.zeros(len(outgroup_seq))\n",
    "    \n",
    "    #at each site, record Pi\n",
    "    Pi_all = np.zeros(len(outgroup_seq))\n",
    "    \n",
    "    for pos in range(len(outgroup_seq)):\n",
    "        outgroup_nt = outgroup_seq[pos]\n",
    "        ingroup_nts = ingroup_bases[pos]\n",
    "        Fi, Pi = fixation_polymorphism_score(outgroup_nt, ingroup_nts)\n",
    "        Fi_all[pos] = Fi\n",
    "        Pi_all[pos] = Pi\n",
    "        \n",
    "    return Fi_all, Pi_all\n",
    "    \n",
    "    \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_site_stats(cov, gene, window):\n",
    "    #Find percent polymorphism at each site\n",
    "    #Also determine whether polymorphism is silent or replacement\n",
    "    input_file_outgroup = '../'+str(cov)+'/auspice/seasonal_corona_'+str(cov)+'_'+str(gene)+'_root-sequence.json'\n",
    "    input_file_alignment = '../'+str(cov)+'/results/aligned_'+str(cov)+'_'+str(gene)+'.fasta'\n",
    "    metafile = '../'+str(cov)+'/results/metadata_'+str(cov)+'_'+str(gene)+'.tsv'\n",
    "\n",
    "    #Subset data based on time windows\n",
    "    meta = pd.read_csv(metafile, sep = '\\t')\n",
    "    meta.drop(meta[meta['date']=='?'].index, inplace=True)\n",
    "    meta.dropna(subset=['date'], inplace=True)\n",
    "    meta['year'] = meta['date'].str[:4].astype('int')\n",
    "    date_range = meta['year'].max() - meta['year'].min()\n",
    "    \n",
    "    #Group viruses by time windows\n",
    "    virus_time_subset = {}\n",
    "    if window == 'all':\n",
    "        years = str(meta['year'].min()) + '-' + str(meta['year'].max())\n",
    "        virus_time_subset[years] = meta['strain'].tolist()\n",
    "    else:\n",
    "        date_window_start = meta['year'].min()\n",
    "        date_window_end = meta['year'].min() + window\n",
    "        while date_window_end <= meta['year'].max():\n",
    "            years = str(date_window_start) + '-' + str(date_window_end)\n",
    "            strains = meta[(meta['year']>=date_window_start) & (meta['year']<date_window_end)]['strain'].tolist()\n",
    "            virus_time_subset[years] = strains\n",
    "            #sliding window\n",
    "            date_window_end += 1\n",
    "            date_window_start += 1   \n",
    "    \n",
    "    #Find outgroup sequence\n",
    "    outgroup_seq = ''\n",
    "    outgroup_aa_seq = ''\n",
    "    with open(input_file_outgroup, \"r\") as outgroup_handle:\n",
    "        outgroup = json.load(outgroup_handle)\n",
    "        outgroup_seq = SeqRecord(Seq(outgroup['nuc']))\n",
    "        outgroup_aa_seq = outgroup_seq.translate()\n",
    "\n",
    "    #initiate lists to record all time windows\n",
    "    year_windows = []\n",
    "    seqs_in_window = []\n",
    "    frequency_bins = []\n",
    "    fixation_scores = []\n",
    "    polymorphism_scores = []\n",
    "    replacement_scores = []\n",
    "    silent_scores = []    \n",
    "        \n",
    "    #each time window separately\n",
    "    for years, subset_viruses in virus_time_subset.items():\n",
    "        if len(subset_viruses) != 0:\n",
    "            year_windows.append(years)\n",
    "            seqs_in_window.append(len(subset_viruses))\n",
    "            \n",
    "            freq_bins, replacement_score, ingroup_bases = walk_through_sites(outgroup_seq, outgroup_aa_seq, \n",
    "                                                                             input_file_alignment, subset_viruses)\n",
    "            Fi_all, Pi_all = assign_fi_pi(outgroup_seq, ingroup_bases)\n",
    "            silent_score = 1-replacement_score\n",
    "            \n",
    "            frequency_bins.append(freq_bins)\n",
    "            fixation_scores.append(Fi_all)\n",
    "            polymorphism_scores.append(Pi_all)\n",
    "            replacement_scores.append(replacement_score)\n",
    "            silent_scores.append(silent_score)\n",
    "            \n",
    "    return year_windows, seqs_in_window, frequency_bins, fixation_scores, polymorphism_scores, replacement_scores, silent_scores\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#M=rm/sm \n",
    "#not expected to vary through time provided that long-term effective population sizes remain sufficiently large\n",
    "#For each gene, calculate M by combining site count among time points\n",
    "\n",
    "def calc_m_ratio(cov, gene):\n",
    "    if gene=='spike' or gene=='s1':\n",
    "        (year_windows, seqs_in_window, frequency_bins, \n",
    "         fixation_scores, polymorphism_scores, replacement_scores, silent_scores) = calc_site_stats(cov, 's2', 'all')\n",
    "    else:\n",
    "        (year_windows, seqs_in_window, frequency_bins, \n",
    "         fixation_scores, polymorphism_scores, replacement_scores, silent_scores) = calc_site_stats(cov, gene, 'all')\n",
    "    \n",
    "    sm = 0\n",
    "    rm = 0\n",
    "    \n",
    "    for site in range(len(frequency_bins[0])):\n",
    "        freq_bin = frequency_bins[0][site]\n",
    "        if freq_bin == 'm':\n",
    "            sm+= (polymorphism_scores[0][site]*silent_scores[0][site])\n",
    "            rm+= (polymorphism_scores[0][site]*replacement_scores[0][site])\n",
    "    \n",
    "    m_ratio = rm/sm\n",
    "    \n",
    "    return m_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bhatt_estimators(cov, gene, window):\n",
    "    (year_windows, seqs_in_window, frequency_bins, \n",
    "     fixation_scores, polymorphism_scores, \n",
    "     replacement_scores, silent_scores) = calc_site_stats(cov, gene, window)\n",
    "    \n",
    "    m_ratio = calc_m_ratio(cov, gene)\n",
    "    \n",
    "    #Initiate lists to store a values\n",
    "    window_midpoint = []\n",
    "    adaptive_substitutions = []\n",
    "    \n",
    "    #for each window, calculate bhatt estimators \n",
    "    for years_window in range(len(frequency_bins)):\n",
    "        #don't use windows with fewer than 5 sequences\n",
    "        if seqs_in_window[years_window] >= 5:\n",
    "            window_start = int(year_windows[years_window][0:4])\n",
    "            window_end = int(year_windows[years_window][-4:])\n",
    "            window_midpoint.append((window_start + window_end)/2)\n",
    "\n",
    "            sf = 0\n",
    "            rf = 0\n",
    "            sh = 0\n",
    "            rh = 0\n",
    "            sm = 0\n",
    "            rm = 0\n",
    "            sl = 0\n",
    "            rl = 0\n",
    "\n",
    "            #calculate number of sites in different catagories (defined by polymorphic freq at that site)\n",
    "            window_freq_bins = frequency_bins[years_window]\n",
    "            for site in range(len(window_freq_bins)):\n",
    "                freq_bin = window_freq_bins[site]\n",
    "                #ignore sites with no polymorphisms?\n",
    "                if freq_bin!='nan':\n",
    "                    if freq_bin == 'f':\n",
    "                        sf+= (fixation_scores[years_window][site]*silent_scores[years_window][site])\n",
    "                        rf+= (fixation_scores[years_window][site]*replacement_scores[years_window][site])\n",
    "                    elif freq_bin == 'h':\n",
    "                        sh+= (polymorphism_scores[years_window][site]*silent_scores[years_window][site])\n",
    "                        rh+= (polymorphism_scores[years_window][site]*replacement_scores[years_window][site])\n",
    "                    elif freq_bin == 'm':\n",
    "                        sm+= (polymorphism_scores[years_window][site]*silent_scores[years_window][site])\n",
    "                        rm+= (polymorphism_scores[years_window][site]*replacement_scores[years_window][site])\n",
    "                    elif freq_bin == 'l':\n",
    "                        sl+= (polymorphism_scores[years_window][site]*silent_scores[years_window][site])\n",
    "                        rl+= (polymorphism_scores[years_window][site]*replacement_scores[years_window][site])       \n",
    "                        \n",
    "#             print(year_windows[years_window])\n",
    "#             print(sf, rf, sh, rh, sm, rm, sl, rl)  \n",
    "\n",
    "            #Calculate equation 1: number of nonneutral sites\n",
    "            al = rl - sl*m_ratio\n",
    "            ah = rh - sh*m_ratio\n",
    "            af = rf - sf*m_ratio\n",
    "            #set negative a values to zero\n",
    "            if al < 0:\n",
    "                al = 0\n",
    "            if ah < 0:\n",
    "                ah = 0\n",
    "            if af < 0:\n",
    "                af = 0\n",
    "\n",
    "#             print(al, ah, af)\n",
    "\n",
    "            #Calculate the number and proportion of all fixed or high-freq sites that have undergone adaptive change\n",
    "            number_adaptive_substitutions = af + ah\n",
    "            adaptive_substitutions.append(number_adaptive_substitutions)\n",
    "            proportion_adaptive_sites = (af + ah)/(rf +rh)\n",
    "            \n",
    "    # get coeffs of linear fit\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(window_midpoint, adaptive_substitutions)\n",
    "    \n",
    "    ax = sns.regplot(x= window_midpoint, y=adaptive_substitutions, \n",
    "                     line_kws={'label':\"y={0:.1f}x+{1:.1f}\".format(slope,intercept)})\n",
    "    plt.ylabel('number of adaptive substitutions')\n",
    "    plt.xlabel('year')\n",
    "    \n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
