Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	align
	1	all
	1	ancestral
	1	download
	1	export
	1	filter
	1	parse
	1	refine
	1	translate
	1	tree
	10

[Wed Jun  3 10:02:54 2020]
Job 8: Downloading sequences from fauna

[Wed Jun  3 10:02:55 2020]
Error in rule download:
    jobid: 8
    output: data/measles.fasta
    shell:
        
        python3 ../fauna/vdb/download.py             --database vdb             --virus measles             --fasta_fields strain virus accession collection_date region country division location source locus authors url title journal puburl             --resolve_method choose_genbank             --path $(dirname data/measles.fasta)             --fstem $(basename data/measles.fasta .fasta)
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /Users/katekistler/nextstrain/measles/.snakemake/log/2020-06-03T100254.669785.snakemake.log
